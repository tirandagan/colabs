{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMZkyHxCA2tWMfjdlhYC7P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirandagan/colabs/blob/main/AI_Lab_3_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading a file\n",
        "\n",
        "This code will download a file into the sample_data folder\n"
      ],
      "metadata": {
        "id": "c1Fp76F4e4w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "def download_file(url, folder=\"sample_data\"):\n",
        "    # Create the folder if it doesn't exist\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    # Get the filename from the URL\n",
        "    filename = os.path.basename(urlparse(url).path)\n",
        "\n",
        "    # Full path for the file\n",
        "    file_path = os.path.join(folder, filename)\n",
        "\n",
        "    # Download the file\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    # Write the file\n",
        "    with open(file_path, 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "\n",
        "    print(f\"File downloaded successfully: {file_path}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_url = \"https://watertechcorp.com/wp-content/uploads/pdf/10000AB.OP21.7L.pdf\"\n",
        "    download_file(file_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B5Oz13Ie24d",
        "outputId": "9b4c2bff-c853-49c5-8324-281a7e359414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully: sample_data2/10000AB.OP21.7L.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing a PDF\n",
        "1.\tImport a pdf using pdfplumber using given code\n"
      ],
      "metadata": {
        "id": "kXvAfkzCaGpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber"
      ],
      "metadata": {
        "id": "4Foq5DTaajnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a04c81-8730-47f9-c051-81e331c8c3d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber as pp\n",
        "\n",
        "with pp.open('sample_data/10000AB.OP21.7L.pdf') as book:\n",
        "    for page_no, page in enumerate(book.pages, start=1):\n",
        "        print(f'{page_no = }')\n",
        "        data = page.extract_text()\n",
        "        print(data.strip())\n",
        "        print('-'*45)"
      ],
      "metadata": {
        "id": "8jdGBcA5aaun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Detection\n",
        "Detecting language using langdetect"
      ],
      "metadata": {
        "id": "A5kO4SMKaQeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langdetect"
      ],
      "metadata": {
        "id": "E-9AiWmddK5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ecd9ac-5c86-4d16-8540-bdb0b4b6b375"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect\n",
        "\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return \"Unable to detect language\"\n",
        "\n",
        "# Example usage\n",
        "text1 = \"1. Coperchio testa 4. Compartimento batteria\"\n",
        "text2 = \"Non gettare nei cassonetti dei rifiuti indifferenziati. Per gli elementi contenenti batterie rimovibili, rimuovere le batterie\"\n",
        "text3 = \"1. Lesen und verstehen Sie alle Sicherheitswarnungen vor dem Betrieb. Andernfalls kann es zu schweren PersonenschÃ¤den\"\n",
        "\n",
        "print(detect_language(text1))\n",
        "print(detect_language(text2))\n",
        "print(detect_language(text3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2ejL9WFdDrb",
        "outputId": "85174beb-efc0-4fb1-f51a-96875799b5aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it\n",
            "it\n",
            "de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\tCombine both #1 and #2 to detect the language for each page read, and only print out english language text\n"
      ],
      "metadata": {
        "id": "DA14EudAaQwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber as pp\n",
        "from langdetect import detect\n",
        "\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return \"Unable to detect language\"\n",
        "with pp.open('sample_data/10000AB.OP21.7L.pdf') as book:\n",
        "    for page_no, page in enumerate(book.pages, start=1):\n",
        "        print(f'{page_no = }')\n",
        "        data = page.extract_text()\n",
        "        lang=detect_language(data.strip())\n",
        "        if lang==\"en\":\n",
        "            print(f\"${data} * ${lang}\")\n",
        "            print('-'*45)\n",
        "        else:\n",
        "            print (f\"ignoring [${lang}]\")"
      ],
      "metadata": {
        "id": "4-bG0lAAeNZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the problem? We have lines with mixed languages. Let's prompt LLM to modfy our code:\n",
        "\n",
        "\n",
        "\n",
        "> This code provide me with output which only include english language text extracted from a page. There are pages that have mixed sentances. Please modify the code so it parses each line separately for language detection and then combines them into a single string represnting that page.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import pdfplumber as pp\n",
        "from langdetect import detect\n",
        "\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return \"Unable to detect language\"\n",
        "with pp.open('test_data/10000AB.OP21.7L.pdf') as book:\n",
        "    for page_no, page in enumerate(book.pages, start=1):\n",
        "        print(f'{page_no = }')\n",
        "        data = page.extract_text()\n",
        "        lang=detect_language(data.strip())\n",
        "        if lang==\"en\":\n",
        "            print(f\"${data} * ${lang}\")\n",
        "            print('-'*45)\n",
        "        else:\n",
        "            print (f\"ignoring [${lang}]\")\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SaLm6J4faQy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's the code that Claude/ChatGPT gave me:\n"
      ],
      "metadata": {
        "id": "Q_48_gAwiFrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber as pp\n",
        "from langdetect import detect\n",
        "from langdetect.lang_detect_exception import LangDetectException\n",
        "\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except LangDetectException:\n",
        "        return \"unknown\"\n",
        "\n",
        "def process_page(page):\n",
        "    data = page.extract_text()\n",
        "    lines = data.split('\\n')\n",
        "    processed_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            lang = detect_language(line)\n",
        "            processed_lines.append(f\"[{lang}] {line}\")\n",
        "\n",
        "    return '\\n'.join(processed_lines)\n",
        "\n",
        "with pp.open('sample_data/10000AB.OP21.7L.pdf') as book:\n",
        "    for page_no, page in enumerate(book.pages, start=1):\n",
        "        print(f'Page {page_no}:')\n",
        "        processed_content = process_page(page)\n",
        "        print(processed_content)\n",
        "        print('-' * 45)"
      ],
      "metadata": {
        "id": "GmuXx99HgDNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now ask LLM to modify your code so it will accept the filename as an argument, and another argument specifying which language (codes) you would to produce as an output, for example:\n",
        "\n",
        "\n",
        "```\n",
        "python sample_data/10000AB.OP21.7L.pdf -l en,de\n",
        "```\n",
        "\n",
        "This should ingest the pdf file, and only output lines that are in English or German (de)"
      ],
      "metadata": {
        "id": "ku54izJEieER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber as pp\n",
        "from langdetect import detect\n",
        "from langdetect.lang_detect_exception import LangDetectException\n",
        "import argparse\n",
        "\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except LangDetectException:\n",
        "        return \"unknown\"\n",
        "\n",
        "def process_page(page, target_languages):\n",
        "    data = page.extract_text()\n",
        "    lines = data.split('\\n')\n",
        "    processed_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            lang = detect_language(line)\n",
        "            if not target_languages or lang in target_languages:\n",
        "                processed_lines.append(f\"[{lang}] {line}\")\n",
        "\n",
        "    return '\\n'.join(processed_lines)\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Process a PDF file and filter content by language.\")\n",
        "    parser.add_argument(\"pdf_file\", help=\"Path to the PDF file\")\n",
        "    parser.add_argument(\"-l\", \"--languages\", help=\"Comma-separated list of language codes to include (e.g., 'en,fr,de')\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    target_languages = args.languages.split(',') if args.languages else []\n",
        "\n",
        "    with pp.open(args.pdf_file) as book:\n",
        "        for page_no, page in enumerate(book.pages, start=1):\n",
        "            print(f'Page {page_no}:')\n",
        "            processed_content = process_page(page, target_languages)\n",
        "            if processed_content:\n",
        "                print(processed_content)\n",
        "                print('-' * 45)\n",
        "            else:\n",
        "                print(\"No content in specified language(s) on this page.\")\n",
        "                print('-' * 45)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "fcyfd69hiRtm",
        "outputId": "57db074f-b298-4ea0-b02c-27f79d83b8fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [-l LANGUAGES] pdf_file\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}